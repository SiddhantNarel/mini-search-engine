# Mini Search Engine

A lightweight, fully-functional search engine built in Python as a 4th-year undergraduate project.  
It demonstrates core information-retrieval concepts: **web crawling**, **text preprocessing**, **inverted indexing**, and **TF-IDF ranking**, all wired up to a clean **Flask web interface**.

---

## Architecture

```
Web Crawler â†’ Tokenizer/Preprocessor â†’ Inverted Index Builder â†’ TF-IDF Ranker â†’ Flask Web UI
```

---

## Features

- ğŸ•· **Web Crawler** â€“ BFS crawl within a single domain, respects `robots.txt`
- ğŸ§¹ **Text Preprocessor** â€“ lowercasing, stop-word removal, suffix-stripping stemmer (no NLTK needed)
- ğŸ“š **Inverted Index** â€“ stores `{term: {doc_id: [positions]}}` with document-frequency counts
- ğŸ“Š **TF-IDF Ranking** â€“ implemented from scratch (no sklearn)
- ğŸŒ **Flask Web UI** â€“ search bar, results page, crawl-trigger form
- ğŸ’¾ **Sample Index** â€“ works out of the box with 15 pre-built Wikipedia documents
- ğŸ–¥ **CLI** â€“ `crawl`, `search`, `runserver`, and `stats` commands

---

## Project Structure

```
mini-search-engine/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ config.py           â† all constants/settings
â”œâ”€â”€ main.py             â† CLI entry point
â”œâ”€â”€ crawler.py          â† web crawler
â”œâ”€â”€ preprocessor.py     â† tokeniser + stemmer
â”œâ”€â”€ indexer.py          â† inverted index builder
â”œâ”€â”€ ranker.py           â† TF-IDF scoring
â”œâ”€â”€ search_engine.py    â† ties everything together
â”œâ”€â”€ app.py              â† Flask web application
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.html
â”‚   â”œâ”€â”€ index.html      â† homepage
â”‚   â”œâ”€â”€ results.html    â† search results
â”‚   â””â”€â”€ crawl.html      â† crawl-trigger form
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css       â† custom CSS (no frameworks)
â””â”€â”€ data/
    â””â”€â”€ sample_index.json  â† pre-built sample index
```

---

## Setup & Installation

```bash
# 1. Clone the repository
git clone https://github.com/SiddhantNarel/mini-search-engine.git
cd mini-search-engine

# 2. Create and activate a virtual environment
python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt
```

---

## Usage

### Web UI (recommended)

```bash
python main.py runserver
# Then open http://localhost:5000 in your browser
```

### Command-line

```bash
# Search the built-in sample index
python main.py search "machine learning"
python main.py search "web crawler python" --top 5

# Crawl a website and rebuild the index
python main.py crawl https://en.wikipedia.org/wiki/Python_(programming_language)
python main.py crawl https://example.com --depth 1 --pages 10

# Show index statistics
python main.py stats
```

---

## How It Works

| Component | File | Description |
|-----------|------|-------------|
| Configuration | `config.py` | Central constants (depths, paths, limits) |
| Crawler | `crawler.py` | BFS over a domain, honours `robots.txt`, saves page JSON |
| Preprocessor | `preprocessor.py` | Lowercase â†’ remove punctuation â†’ stop words â†’ stem |
| Indexer | `indexer.py` | Builds `{term â†’ {doc_id â†’ [positions]}}` + DF table |
| Ranker | `ranker.py` | TF-IDF: `TF Ã— log((N+1)/(df+1)) + 1` per query term |
| Search Engine | `search_engine.py` | Loads index, preprocesses query, calls ranker |
| Web UI | `app.py` + `templates/` | Flask routes + Jinja2 templates |
| CLI | `main.py` | `argparse`-based command-line interface |

---

## Technologies Used

- **Python 3.8+**
- **Flask** â€“ web framework
- **Requests** â€“ HTTP client for the crawler
- **BeautifulSoup4 + lxml** â€“ HTML parsing
- Standard library only for everything else (`re`, `json`, `math`, `urllib`, â€¦)

---

## Possible Improvements / Future Work

- Phrase queries (`"exact phrase"`) using positional index information
- Boolean operators (`AND`, `OR`, `NOT`)
- PageRank-style link-graph scoring
- Persistent crawl queue (resume after interruption)
- Autocomplete via a trie data structure
- Pagination on the results page
- Docker container for easy deployment
